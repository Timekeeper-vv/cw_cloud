# å¼‚å¸¸ç»“æœå®Œæ•´è¯´æ˜æ–‡æ¡£

## ğŸ¯ æ ¸å¿ƒé—®é¢˜ï¼šå¼‚å¸¸ç»“æœåœ¨å“ªé‡Œï¼Ÿ

### ç®€çŸ­å›ç­”

**å¼‚å¸¸ç»“æœåœ¨3ä¸ªåœ°æ–¹**ï¼š

1. **ç”Ÿæˆä½ç½®**: `AnomalyDetector.detect()` æ–¹æ³•ï¼ˆç¬¬50-56è¡Œï¼‰
2. **å¤„ç†ä½ç½®**: `StreamProcessor.processStream()` æ–¹æ³•ï¼ˆç¬¬120-167è¡Œï¼‰
3. **è¾“å‡ºä½ç½®**: 
   - Kafka Topic: `anomaly-detection-result`
   - æ—¥å¿—æ–‡ä»¶: `logs/spark-streaming.log`
   - å®æ—¶ç»Ÿè®¡: æ§åˆ¶å°è¾“å‡º

---

## ğŸ“ è¯¦ç»†ä½ç½®è¯´æ˜

### 1. å¼‚å¸¸ç»“æœç”Ÿæˆï¼ˆæ ¸å¿ƒä»£ç ï¼‰

**æ–‡ä»¶**: `src/main/java/com/floatdata/processor/AnomalyDetector.java`

```java
public AnomalyResult detect(SignalData signalData) {
    float[] samples = signalData.getSamples();
    
    // æ­¥éª¤1: Butterworthæ»¤æ³¢
    float[] filtered = filter.applyButterworthFilter(samples);
    
    // æ­¥éª¤2: è®¡ç®—èƒ½é‡
    double energy = filter.calculateEnergy(filtered);
    double normalizedEnergy = normalizeEnergy(energy);
    
    // æ­¥éª¤3: FFTé¢‘ç‡åˆ†æ
    double[] frequencyMagnitude = filter.calculateFrequencyFeatures(filtered);
    double frequencyScore = filter.calculateFrequencyScore(frequencyMagnitude);
    
    // â­â­â­ æ­¥éª¤4: åˆ›å»ºå¼‚å¸¸ç»“æœå¯¹è±¡ï¼ˆè¿™å°±æ˜¯å¼‚å¸¸ç»“æœï¼ï¼‰
    AnomalyResult result = new AnomalyResult(
        signalData.getTimestamp(),    // æ—¶é—´æˆ³
        signalData.getSensorId(),     // ä¼ æ„Ÿå™¨ID
        signalData.getLocation(),     // ä½ç½®
        normalizedEnergy,             // èƒ½é‡æ°´å¹³ (0-1)
        frequencyScore                // é¢‘ç‡å¾—åˆ† (0-1)
    );
    
    return result;  // è¿”å›å¼‚å¸¸ç»“æœ
}
```

### 2. å¼‚å¸¸ç»“æœæ•°æ®ç»“æ„

**æ–‡ä»¶**: `src/main/java/com/floatdata/utils/AnomalyResult.java`

```java
public class AnomalyResult {
    private long timestamp;           // æ—¶é—´æˆ³
    private int sensorId;            // ä¼ æ„Ÿå™¨ID  
    private String location;         // ä½ç½®
    private double energyLevel;      // èƒ½é‡æ°´å¹³ (0-1)
    private double frequencyScore;   // é¢‘ç‡å¾—åˆ† (0-1)
    private double anomalyScore;     // ç»¼åˆå¼‚å¸¸åˆ†æ•° (0-1) â­
    private boolean isAnomaly;       // æ˜¯å¦å¼‚å¸¸ â­â­â­
    private String anomalyType;      // å¼‚å¸¸ç±»å‹ â­
    private long processingTime;     // å¤„ç†æ—¶é—´(ms)
}
```

**å¼‚å¸¸åˆ¤å®šé€»è¾‘**ï¼ˆåœ¨æ„é€ å‡½æ•°ä¸­ï¼‰ï¼š
```java
// è®¡ç®—ç»¼åˆå¼‚å¸¸åˆ†æ•°
this.anomalyScore = (energyLevel + frequencyScore) / 2.0;

// åˆ¤å®šæ˜¯å¦å¼‚å¸¸ï¼ˆé˜ˆå€¼ï¼š0.75ï¼‰
this.isAnomaly = this.anomalyScore > 0.75;

// åˆ†ç±»å¼‚å¸¸ç±»å‹
private String determineAnomalyType() {
    if (!isAnomaly) return "NORMAL";              // æ­£å¸¸
    if (energyLevel > 0.8) return "HIGH_ENERGY";  // é«˜èƒ½é‡å¼‚å¸¸
    if (frequencyScore > 0.8) return "FREQUENCY_ANOMALY"; // é¢‘ç‡å¼‚å¸¸
    return "MIXED_ANOMALY";                       // æ··åˆå¼‚å¸¸
}
```

### 3. å¼‚å¸¸ç»“æœå¤„ç†æµç¨‹

**æ–‡ä»¶**: `src/main/java/com/floatdata/spark/StreamProcessor.java`

```java
// â­ æ­¥éª¤1: åœ¨Sparkä¸­å¹¶è¡Œæ‰§è¡Œå¼‚å¸¸æ£€æµ‹
JavaDStream<AnomalyResult> resultStream = segmentedStream
    .flatMap(signalList -> {
        // æ¯ä¸ªExecutorè¿›ç¨‹ç‹¬ç«‹è¿è¡Œ
        AnomalyDetector detector = new AnomalyDetector();
        List<AnomalyResult> results = new ArrayList<>();
        
        for (SignalData signal : signalList) {
            AnomalyResult result = detector.detect(signal); // ç”Ÿæˆå¼‚å¸¸ç»“æœ
            results.add(result);
        }
        
        return results.iterator();
    });

// â­ æ­¥éª¤2: è¾“å‡ºå¼‚å¸¸ç»“æœåˆ°å¤šä¸ªæ¸ é“
resultStream.foreachRDD(rdd -> {
    rdd.foreach(result -> {
        // è¾“å‡º1: å‘é€åˆ°Kafka
        sendResultToKafka(result);
        
        // è¾“å‡º2: è®°å½•å¼‚å¸¸æ—¥å¿—
        if (result.isAnomaly()) {
            logger.warn("æ£€æµ‹åˆ°å¼‚å¸¸: {}", result);
        }
    });
    
    // è¾“å‡º3: æ‰¹æ¬¡ç»Ÿè®¡
    long count = rdd.count();
    long anomalyCount = rdd.filter(AnomalyResult::isAnomaly).count();
    logger.info("æ‰¹æ¬¡å¤„ç†: æ€»æ•°={}, å¼‚å¸¸={}, å¼‚å¸¸ç‡={:.2f}%",
            count, anomalyCount, (double) anomalyCount / count * 100);
});

// â­ æ­¥éª¤3: å‘¨æœŸç»Ÿè®¡ï¼ˆæ¯10ç§’ï¼‰
resultStream.window(Durations.seconds(10))
    .foreachRDD(rdd -> {
        Map<String, Long> anomalyTypeCount = rdd
                .filter(AnomalyResult::isAnomaly)
                .mapToPair(r -> new Tuple2<>(r.getAnomalyType(), 1L))
                .reduceByKey((a, b) -> a + b)
                .collectAsMap();
        
        logger.info("å¼‚å¸¸ç±»å‹ç»Ÿè®¡: {}", anomalyTypeCount);
    });
```

---

## ğŸ“¤ å¼‚å¸¸ç»“æœçš„4ä¸ªè¾“å‡ºæ¸ é“

### è¾“å‡º1: Kafka Topicï¼ˆç»“æ„åŒ–å­˜å‚¨ï¼‰

**Topicåç§°**: `anomaly-detection-result`

**æ¶ˆæ¯æ ¼å¼**ï¼ˆJSONï¼‰:
```json
{
  "timestamp": 1700123456789,
  "sensorId": 1,
  "location": "center",
  "energyLevel": 0.85,
  "frequencyScore": 0.78,
  "anomalyScore": 0.815,
  "isAnomaly": true,
  "anomalyType": "HIGH_ENERGY",
  "processingTime": 15
}
```

**æŸ¥çœ‹æ–¹æ³•**:
```powershell
# æ–¹æ³•1: ä½¿ç”¨ç›‘æ§è„šæœ¬
.\monitor.ps1

# æ–¹æ³•2: ç›´æ¥æŸ¥çœ‹Kafka
kafka_3.6.0\bin\windows\kafka-console-consumer.bat `
    --bootstrap-server localhost:9092 `
    --topic anomaly-detection-result `
    --from-beginning
```

### è¾“å‡º2: æ—¥å¿—æ–‡ä»¶ï¼ˆå®æ—¶è®°å½•ï¼‰

**æ–‡ä»¶ä½ç½®**: `logs/spark-streaming.log`

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-11-17 09:40:15 WARN  æ£€æµ‹åˆ°å¼‚å¸¸: AnomalyResult{
  timestamp=1700123456789, 
  sensorId=1, 
  location='center', 
  energyLevel=0.8500, 
  frequencyScore=0.7800, 
  anomalyScore=0.8150, 
  isAnomaly=true, 
  anomalyType='HIGH_ENERGY', 
  processingTime=15ms
}
```

**æŸ¥çœ‹æ–¹æ³•**:
```powershell
# å®æ—¶æŸ¥çœ‹å¼‚å¸¸
Get-Content logs\spark-streaming.log -Wait | Select-String "æ£€æµ‹åˆ°å¼‚å¸¸"

# æŸ¥çœ‹æ‰€æœ‰å¼‚å¸¸
Get-Content logs\spark-streaming.log | Select-String "Anomaly detected"
```

### è¾“å‡º3: æ‰¹æ¬¡ç»Ÿè®¡ï¼ˆæ¯æ‰¹æ¬¡ï¼‰

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-11-17 09:40:15 INFO  æ‰¹æ¬¡å¤„ç†: æ€»æ•°=1000, å¼‚å¸¸=23, å¼‚å¸¸ç‡=2.30%
2025-11-17 09:40:17 INFO  æ‰¹æ¬¡å¤„ç†: æ€»æ•°=980, å¼‚å¸¸=18, å¼‚å¸¸ç‡=1.84%
```

**æŸ¥çœ‹æ–¹æ³•**:
```powershell
Get-Content logs\spark-streaming.log | Select-String "æ‰¹æ¬¡å¤„ç†"
```

### è¾“å‡º4: å‘¨æœŸç»Ÿè®¡ï¼ˆæ¯10ç§’ï¼‰

**æ—¥å¿—ç¤ºä¾‹**:
```
2025-11-17 09:40:20 INFO  å¼‚å¸¸ç±»å‹ç»Ÿè®¡: {
  HIGH_ENERGY=15, 
  FREQUENCY_ANOMALY=8, 
  MIXED_ANOMALY=5
}
```

**æŸ¥çœ‹æ–¹æ³•**:
```powershell
Get-Content logs\spark-streaming.log | Select-String "å¼‚å¸¸ç±»å‹ç»Ÿè®¡"
```

---

## ğŸ” å¦‚ä½•æŸ¥çœ‹å’Œåˆ†æå¼‚å¸¸ç»“æœ

### æ–¹æ³•1: å®æ—¶ç›‘æ§ï¼ˆæ¨èï¼‰

```powershell
# æ‰“å¼€3ä¸ªPowerShellçª—å£

# çª—å£1: è¿è¡Œç³»ç»Ÿ
.\start.ps1

# çª—å£2: å®æ—¶æŸ¥çœ‹å¼‚å¸¸
Get-Content logs\spark-streaming.log -Wait | Select-String "å¼‚å¸¸"

# çª—å£3: ç›‘æ§Kafkaæ¶ˆæ¯
.\monitor.ps1
```

### æ–¹æ³•2: äº‹ååˆ†æ

```powershell
# ç»Ÿè®¡æ€»å¤„ç†é‡
$logs = Get-Content logs\spark-streaming.log

# æå–æ‰€æœ‰æ‰¹æ¬¡å¤„ç†è®°å½•
$batches = $logs | Select-String "æ‰¹æ¬¡å¤„ç†: æ€»æ•°=(\d+), å¼‚å¸¸=(\d+)"

# è®¡ç®—æ€»å¼‚å¸¸æ•°
$totalAnomalies = 0
foreach ($line in $batches) {
    if ($line -match "å¼‚å¸¸=(\d+)") {
        $totalAnomalies += [int]$matches[1]
    }
}

Write-Host "æ€»æ£€æµ‹å¼‚å¸¸æ•°: $totalAnomalies"
```

### æ–¹æ³•3: ç¼–ç¨‹æ–¹å¼æ¶ˆè´¹Kafka

åˆ›å»ºæ¶ˆè´¹è€…ç¨‹åºè¯»å–å¼‚å¸¸ç»“æœï¼š

```java
// æ–‡ä»¶: src/main/java/com/floatdata/client/AnomalyResultConsumer.java
public class AnomalyResultConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "anomaly-consumer");
        props.put("key.deserializer", StringDeserializer.class);
        props.put("value.deserializer", StringDeserializer.class);
        
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("anomaly-detection-result"));
        
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                // è§£æå¼‚å¸¸ç»“æœ
                AnomalyResult result = AnomalyResult.fromJson(record.value());
                
                // å¤„ç†å¼‚å¸¸
                if (result.isAnomaly()) {
                    System.out.println("âš ï¸ å¼‚å¸¸å‘Šè­¦: " + result);
                    // å¯ä»¥æ·»åŠ ï¼šå‘é€é‚®ä»¶ã€çŸ­ä¿¡ã€æ¨é€é€šçŸ¥ç­‰
                }
            }
        }
    }
}
```

---

## ğŸ“Š å¼‚å¸¸ç»“æœç¤ºä¾‹

### æ­£å¸¸ä¿¡å·
```json
{
  "timestamp": 1700123456789,
  "sensorId": 1,
  "location": "center",
  "energyLevel": 0.45,          // èƒ½é‡æ­£å¸¸
  "frequencyScore": 0.52,       // é¢‘ç‡æ­£å¸¸
  "anomalyScore": 0.485,        // < 0.75ï¼Œæ­£å¸¸
  "isAnomaly": false,           // âœ… æ­£å¸¸
  "anomalyType": "NORMAL",
  "processingTime": 12
}
```

### é«˜èƒ½é‡å¼‚å¸¸
```json
{
  "timestamp": 1700123460123,
  "sensorId": 2,
  "location": "edge",
  "energyLevel": 0.92,          // èƒ½é‡å¼‚å¸¸é«˜ï¼
  "frequencyScore": 0.65,
  "anomalyScore": 0.785,        // > 0.75ï¼Œå¼‚å¸¸
  "isAnomaly": true,            // âš ï¸ å¼‚å¸¸
  "anomalyType": "HIGH_ENERGY",
  "processingTime": 15
}
```

### é¢‘ç‡å¼‚å¸¸
```json
{
  "timestamp": 1700123465789,
  "sensorId": 3,
  "location": "corner",
  "energyLevel": 0.68,
  "frequencyScore": 0.88,       // é¢‘ç‡å¼‚å¸¸é«˜ï¼
  "anomalyScore": 0.78,         // > 0.75ï¼Œå¼‚å¸¸
  "isAnomaly": true,            // âš ï¸ å¼‚å¸¸
  "anomalyType": "FREQUENCY_ANOMALY",
  "processingTime": 14
}
```

### æ··åˆå¼‚å¸¸
```json
{
  "timestamp": 1700123470456,
  "sensorId": 1,
  "location": "center",
  "energyLevel": 0.78,          // èƒ½é‡ç•¥é«˜
  "frequencyScore": 0.82,       // é¢‘ç‡ç•¥é«˜
  "anomalyScore": 0.80,         // > 0.75ï¼Œå¼‚å¸¸
  "isAnomaly": true,            // âš ï¸ å¼‚å¸¸
  "anomalyType": "MIXED_ANOMALY",
  "processingTime": 16
}
```

---

## ğŸ¯ æ€»ç»“

### å¼‚å¸¸ç»“æœçš„å®Œæ•´è·¯å¾„

```
1. æ•°æ®é‡‡é›† (æ ·æœº/æ¨¡æ‹Ÿå™¨)
   â””â”€ å‘é€åˆ° Netty:9090

2. Nettyæ¥æ”¶
   â””â”€ è§£æå¹¶å‘é€åˆ° Kafka Topic: acoustic-emission-signal

3. Spark Streamingæ¶ˆè´¹
   â””â”€ ä»Kafkaè¯»å–æ•°æ®

4. æ•°æ®åˆ†æ®µ
   â””â”€ çª—å£åˆ†æ‰¹ â†’ å¤šä¸ªPartition

5. å¹¶è¡Œå¤„ç†ï¼ˆå¤šè¿›ç¨‹ï¼‰
   â”œâ”€ Executor 1 â†’ AnomalyDetector.detect() â†’ ç”ŸæˆAnomalyResult
   â”œâ”€ Executor 2 â†’ AnomalyDetector.detect() â†’ ç”ŸæˆAnomalyResult
   â””â”€ Executor 3 â†’ AnomalyDetector.detect() â†’ ç”ŸæˆAnomalyResult

6. å¼‚å¸¸ç»“æœè¾“å‡º â­â­â­
   â”œâ”€ Kafka Topic: anomaly-detection-result
   â”œâ”€ æ—¥å¿—æ–‡ä»¶: logs/spark-streaming.log  
   â”œâ”€ æ‰¹æ¬¡ç»Ÿè®¡: æ¯2ç§’è¾“å‡ºä¸€æ¬¡
   â””â”€ å‘¨æœŸç»Ÿè®¡: æ¯10ç§’è¾“å‡ºä¸€æ¬¡
```

### å…³é”®æ–‡ä»¶ä½ç½®

| åŠŸèƒ½ | æ–‡ä»¶ä½ç½® | è¯´æ˜ |
|------|---------|------|
| **å¼‚å¸¸æ£€æµ‹** | `AnomalyDetector.java` | æ ¸å¿ƒç®—æ³• |
| **å¼‚å¸¸ç»“æœ** | `AnomalyResult.java` | æ•°æ®ç»“æ„ |
| **æµå¤„ç†** | `StreamProcessor.java` | åˆ†å¸ƒå¼å¤„ç† |
| **æ»¤æ³¢ç®—æ³•** | `SignalFilter.java` | Butterworth + FFT |
| **è¾“å‡ºTopic** | Kafka: `anomaly-detection-result` | ç»“æœå­˜å‚¨ |
| **æ—¥å¿—æ–‡ä»¶** | `logs/spark-streaming.log` | å®æ—¶æ—¥å¿— |

### å¿«é€ŸæŸ¥çœ‹å‘½ä»¤

```powershell
# æŸ¥çœ‹å¼‚å¸¸
Get-Content logs\spark-streaming.log | Select-String "Anomaly detected"

# æŸ¥çœ‹ç»Ÿè®¡
Get-Content logs\spark-streaming.log | Select-String "æ‰¹æ¬¡å¤„ç†"

# ç›‘æ§Kafka
.\monitor.ps1
```
